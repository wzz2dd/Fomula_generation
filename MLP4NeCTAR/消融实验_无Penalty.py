import torch
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from torch import nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import os

# ==========================================
# è¾…åŠ©ï¼šå¯å¾® Spearman Loss
# ==========================================
def differentiable_spearman_loss(pred, target):
    cos_sim = F.cosine_similarity(pred, target, dim=1)
    loss_cos = 1.0 + cos_sim.mean()
    
    n = pred.shape[1]
    idx1 = torch.randint(0, n, (2000,), device=pred.device)
    idx2 = torch.randint(0, n, (2000,), device=pred.device)
    
    diff_target = target[:, idx1] - target[:, idx2]
    diff_pred = pred[:, idx1] - pred[:, idx2]
    
    rank_loss = F.relu(diff_pred * diff_target).mean()
    
    return loss_cos + 2.0 * rank_loss

# ==========================================
# ã€ä¿®æ”¹ç‚¹ 1ã€‘è¾…åŠ©ï¼šåŠ¨æ€ Top-300 æ©ç  (å…¨GPUç‰ˆ)
# ==========================================
def apply_dynamic_mask_torch(vector, limit=300):
    """
    å®Œå…¨åœ¨ GPU ä¸Šè¿è¡Œçš„ Top-N æ©ç å‡½æ•°
    """
    mask = torch.zeros_like(vector, dtype=torch.bool)
    
    # 1. æ­£å‘éƒ¨åˆ†
    pos_mask = vector > 0
    pos_indices = torch.nonzero(pos_mask).squeeze()
    
    if pos_indices.numel() > limit:
        pos_values = vector[pos_indices]
        _, top_k_indices = torch.topk(pos_values, limit)
        mask[pos_indices[top_k_indices]] = True
    else:
        mask[pos_indices] = True

    # 2. è´Ÿå‘éƒ¨åˆ†
    neg_mask = vector < 0
    neg_indices = torch.nonzero(neg_mask).squeeze()
    
    if neg_indices.numel() > limit:
        neg_values = vector[neg_indices]
        _, top_k_indices = torch.topk(neg_values, limit, largest=False)
        mask[neg_indices[top_k_indices]] = True
    else:
        mask[neg_indices] = True
        
    return vector * mask

# ==========================================
# ä¸»ç¨‹åº
# ==========================================
def main():
    # ---------------------------------------------------------
    # ã€ä¿®æ”¹ç‚¹ 2ã€‘å¼ºåˆ¶å•å¡è®¾ç½®
    # ---------------------------------------------------------
    if torch.cuda.is_available():
        device = torch.device('cuda:0')
        print(f"ğŸ”¥ [System] Single GPU Mode: {torch.cuda.get_device_name(0)}")
    else:
        raise RuntimeError("âŒ Error: GPU not found!")
    
    seed = 2025
    torch.manual_seed(seed)
    np.random.seed(seed)
    
    data_path = "é€šè·¯-ä¸­è¯ç»„åˆ_NESçŸ©é˜µ.csv" 
    print(f"ğŸ“š [Data] Loading Matrix from {data_path}...")
    
    try:
        df = pd.read_csv(data_path, index_col=0)
    except:
        df = pd.read_csv(data_path, sep='\t', index_col=0)
    df.fillna(0, inplace=True)
    
    # è‡ªåŠ¨è½¬ç½®æ£€æµ‹
    if df.shape[0] > df.shape[1]: 
        print("âš ï¸ Detected [Rows < Cols], transposing...")
        df = df.T

    # ã€ä¿®æ”¹ç‚¹ 3ã€‘æ•°æ®ç›´æ¥åŠ è½½åˆ° GPU Tensorï¼Œé¿å…è®­ç»ƒæ—¶åå¤æ¬è¿
    herb_matrix_tensor = torch.tensor(df.values.astype(np.float32)).to(device)
    
    num_herbs, num_pathways = herb_matrix_tensor.shape
    print(f"âœ¨ [Dimension] Input: {num_pathways} | Output: {num_herbs}")

    # --- ã€ä¿®æ”¹ç‚¹ 4ã€‘Dataset æ”¹ä¸ºå…¨ GPU ç‰ˆæœ¬ (æå¤§æå‡é€Ÿåº¦) ---
    class AdversarialDatasetGPU(Dataset):
        def __init__(self, herb_matrix, num_samples=60000, max_mix=12):
            self.herb_matrix = herb_matrix # å·²ç»åœ¨ GPU ä¸Š
            self.num_samples = num_samples
            self.max_mix = max_mix
            self.num_herbs = herb_matrix.shape[0]
            self.num_features = herb_matrix.shape[1]

        def __len__(self):
            return self.num_samples

        def __getitem__(self, idx):
            # å…¨ç¨‹ä½¿ç”¨ torch æ“ä½œï¼Œæ— éœ€ CPU å‚ä¸
            
            # 1. éšæœºç»„åˆ
            k = torch.randint(1, self.max_mix + 1, (1,), device=self.herb_matrix.device).item()
            indices = torch.randperm(self.num_herbs, device=self.herb_matrix.device)[:k]
            coeffs = torch.rand(k, device=self.herb_matrix.device) * (3.0 - 0.3) + 0.3
            
            selected_vectors = self.herb_matrix[indices]
            clean_effect = torch.matmul(coeffs, selected_vectors)
            
            # 2. åŸå§‹ç–¾ç—…ä¿¡å·
            raw_disease = -1.0 * clean_effect
            
            # 3. åº”ç”¨åŠ¨æ€ Top-300 æ©ç  (GPUç‰ˆ)
            masked_disease = apply_dynamic_mask_torch(raw_disease, limit=300)
            
            # 4. æ•°å€¼ç¼©æ”¾
            max_val = torch.max(torch.abs(masked_disease))
            if max_val == 0: max_val = 1.0
            
            normalized_disease = masked_disease / max_val
            real_amplitude = torch.rand(1, device=self.herb_matrix.device) * (5.0 - 1.5) + 1.5
            final_input = normalized_disease * real_amplitude
            
            # 5. æ·»åŠ å°‘é‡å™ªéŸ³
            global_noise = torch.randn(self.num_features, device=self.herb_matrix.device) * 0.1
            final_input += global_noise
            
            # 6. æ ‡ç­¾
            target = torch.ones(self.num_herbs, device=self.herb_matrix.device) * 0.01
            target[indices] = 0.99 
            
            return final_input, target, clean_effect

    # --- Model ---
    class ResidualBlock(nn.Module):
        def __init__(self, size, dropout_p=0.4):
            super(ResidualBlock, self).__init__()
            self.block = nn.Sequential(
                nn.Linear(size, size), nn.BatchNorm1d(size), nn.PReLU(),
                nn.Dropout(dropout_p), nn.Linear(size, size), nn.BatchNorm1d(size),
            )
            self.activation = nn.PReLU()
        def forward(self, x): return self.activation(x + self.block(x))

    class AdvancedPredictor(nn.Module):
        def __init__(self, input_size, output_size):
            super(AdvancedPredictor, self).__init__()
            self.entry = nn.Sequential(nn.Linear(input_size, 4096), nn.BatchNorm1d(4096), nn.PReLU(), nn.Dropout(0.3))
            self.compress = nn.Sequential(nn.Linear(4096, 2048), nn.BatchNorm1d(2048), nn.PReLU())
            self.res1 = ResidualBlock(2048)
            self.res2 = ResidualBlock(2048)
            self.res3 = ResidualBlock(2048)
            self.head = nn.Sequential(nn.Linear(2048, 1024), nn.PReLU(), nn.Linear(1024, output_size))
        def forward(self, x):
            x = self.entry(x)
            x = self.compress(x)
            x = self.res1(x)
            x = self.res2(x)
            x = self.res3(x)
            return self.head(x)

    # --- Training ---
    print("ğŸš€ Initializing Top-300 Training (Full GPU)...")
    
    train_dataset = AdversarialDatasetGPU(herb_matrix_tensor, num_samples=60000, max_mix=12)
    test_dataset = AdversarialDatasetGPU(herb_matrix_tensor, num_samples=2000, max_mix=12)
    
    # ã€ä¿®æ”¹ç‚¹ 5ã€‘num_workers=0, pin_memory=False
    # æ•°æ®å·²ç»åœ¨ GPU ä¸Šï¼Œä¸éœ€è¦å¤šè¿›ç¨‹ worker å’Œ pin_memory
    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=0)
    test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=0)
    
    model = AdvancedPredictor(num_pathways, num_herbs).to(device)
    
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)
    
    epochs = 60
    for epoch in range(epochs):
        model.train()
        epoch_loss = 0
        loop = tqdm(train_loader, desc=f"Epoch {epoch+1}")
        
        for inputs, targets, ideal_effects in loop:
            # inputs, targets å·²ç»åœ¨ GPU ä¸Šäº†ï¼Œä¸éœ€è¦ .to(device)
            optimizer.zero_grad()
            logits = model(inputs)
            
            cls_loss = F.binary_cross_entropy_with_logits(logits, targets)
            
            pred_probs = torch.sigmoid(logits)
            # ä½¿ç”¨å…¨å±€ herb_matrix_tensor è®¡ç®—è¯æ•ˆ
            pred_effect = torch.matmul(pred_probs, herb_matrix_tensor)
            rev_loss = differentiable_spearman_loss(pred_effect, inputs)
            
            bad_dir = F.relu(inputs * pred_effect)
            penalty = bad_dir.mean() * 10.0
            
            #total_loss = cls_loss + 0.5 * rev_loss + 0.2 * penalty
            # (æ¶ˆè Penalty)
            total_loss = cls_loss + 0.5 * rev_loss # å»æ‰ penalty

            total_loss.backward()
            optimizer.step()
            epoch_loss += total_loss.item()
            loop.set_postfix(loss=total_loss.item())
            
        avg_loss = epoch_loss / len(train_loader)
        scheduler.step(avg_loss)

    # ã€ä¿®æ”¹ç‚¹ 6ã€‘ä¿å­˜ä¸º Top300
    save_name = 'æ¶ˆèå®éªŒ_Top300_æ— Penalty.pth'
    torch.save(model.state_dict(), save_name)
    print(f"ğŸ’¾ Model Saved as: {save_name}")

if __name__ == "__main__":
    main()